{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "import pandas as pd #dataframes\n",
    "import numpy as np #for arrays \n",
    "\n",
    "#NLP libraries\n",
    "import nltk \n",
    "from nltk.corpus import udhr #corpora with texts \n",
    "import re #Regular expressions\n",
    "import spacy \n",
    "import es_core_news_sm, ko_core_news_sm, fi_core_news_sm, zh_core_web_sm, ja_core_news_sm, pl_core_news_sm, de_core_news_sm #spacy models\n",
    "\n",
    "#NLP objects for (as we can't use shortcuts for loading the objects)\n",
    "nlp_es= spacy.load(\"es_core_news_sm\") #Spanish\n",
    "nlp_ko= spacy.load(\"ko_core_news_sm\") #Korean\n",
    "nlp_fi= spacy.load(\"fi_core_news_sm\") #Finnish\n",
    "nlp_zh= spacy.load(\"zh_core_web_sm\") #Chinese\n",
    "nlp_ja= spacy.load(\"ja_core_news_sm\") #Japanese\n",
    "nlp_pl= spacy.load(\"pl_core_news_sm\") #Polish\n",
    "nlp_de= spacy.load(\"de_core_news_sm\") #German\n",
    "\n",
    "#other spacy models for less explored languages \n",
    "from spacy.lang.tr import Turkish\n",
    "nlp_tr= Turkish()\n",
    "from spacy.lang.id import Indonesian\n",
    "nlp_id= Indonesian()\n",
    "from spacy.lang.ar import Arabic\n",
    "nlp_ar= Arabic()\n",
    "from spacy.lang.tl import Tagalog\n",
    "nlp_tl= Tagalog()\n",
    "from spacy.lang.eu import Basque\n",
    "nlp_eu= Basque()\n",
    "from spacy.lang.et import Estonian\n",
    "nlp_et= Estonian()\n",
    "from spacy.lang.kn import Kannada\n",
    "nlp_kn= Kannada()\n",
    "from spacy.lang.yo import Yoruba \n",
    "nlp_yo= Yoruba()\n",
    "#from spacy.lang.vi import Vietnamese\n",
    "#nlp_vi= Vietnamese()\n",
    "from spacy.lang.ms import Malay\n",
    "nlp_ms= Malay()\n",
    "from spacy.lang.ga import Irish\n",
    "nlp_ga= Irish()\n",
    "from spacy.lang.tn import Setswana\n",
    "nlp_tn= Setswana()\n",
    "from spacy.lang.bg import Bulgarian\n",
    "nlp_bg= Bulgarian()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Tokenizer</th>\n",
       "      <th>Code</th>\n",
       "      <th>Spacy object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>es_core_news_sm</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Korean</td>\n",
       "      <td>Koreanic</td>\n",
       "      <td>ko_core_news_sm</td>\n",
       "      <td>ko</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>Uralic</td>\n",
       "      <td>fi_core_news_sm</td>\n",
       "      <td>fi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Turkic</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>zh_core_web_sm</td>\n",
       "      <td>zh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japonic</td>\n",
       "      <td>ja_core_news_sm</td>\n",
       "      <td>ja</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>ar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tagalog</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Tagalog</td>\n",
       "      <td>tl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Basque</td>\n",
       "      <td>N/D</td>\n",
       "      <td>Basque</td>\n",
       "      <td>eu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Estonian</td>\n",
       "      <td>Uralic</td>\n",
       "      <td>Estonian</td>\n",
       "      <td>et</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kannada</td>\n",
       "      <td>Dravian</td>\n",
       "      <td>Kannada</td>\n",
       "      <td>kn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yoruba</td>\n",
       "      <td>Atlantic-Congo</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>yo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Polish</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>pl_core_news_sm</td>\n",
       "      <td>pl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>German</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>de_core_news_sm</td>\n",
       "      <td>de</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Bulgarian</td>\n",
       "      <td>bg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Setswana</td>\n",
       "      <td>Atlantic-Congo</td>\n",
       "      <td>Setswana</td>\n",
       "      <td>tn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>Viatnamese</td>\n",
       "      <td>vi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Malay</td>\n",
       "      <td>Astronesian</td>\n",
       "      <td>Malay</td>\n",
       "      <td>ms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Irish</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Irish</td>\n",
       "      <td>ga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language          Family        Tokenizer Code  Spacy object\n",
       "0      Spanish   Indo-European  es_core_news_sm   es             1\n",
       "1       Korean        Koreanic  ko_core_news_sm   ko             1\n",
       "2      Finnish          Uralic  fi_core_news_sm   fi             0\n",
       "3      Turkish          Turkic          Turkish   tr             0\n",
       "4   Indonesian    Austronesian       Indonesian   id             0\n",
       "5      Chinese    Sino-Tibetan   zh_core_web_sm   zh             1\n",
       "6     Japanese         Japonic  ja_core_news_sm   ja             1\n",
       "7       Arabic    Austronesian           Arabic   ar             0\n",
       "8      Tagalog    Afro-Asiatic          Tagalog   tl             0\n",
       "9       Basque             N/D           Basque   eu             0\n",
       "10    Estonian          Uralic         Estonian   et             0\n",
       "11     Kannada         Dravian          Kannada   kn             0\n",
       "12      Yoruba  Atlantic-Congo           Yoruba   yo             0\n",
       "13      Polish   Indo-European  pl_core_news_sm   pl             1\n",
       "14      German   Indo-European  de_core_news_sm   de             1\n",
       "15   Bulgarian   Indo-European        Bulgarian   bg             0\n",
       "16    Setswana  Atlantic-Congo         Setswana   tn             0\n",
       "17  Vietnamese   Austroasiatic       Viatnamese   vi             0\n",
       "18       Malay     Astronesian            Malay   ms             0\n",
       "19       Irish   Indo-European            Irish   ga             0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"language_data.csv\", sep=\";\")\n",
    "languages= df['Language'].values\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_texts(list_of_languages):\n",
    "  raw_files_names= {}\n",
    "  for language in list_of_languages:\n",
    "    all_files= nltk.corpus.udhr.fileids()\n",
    "    file= [f for f in all_files if re.findall(language, f)][0]\n",
    "    raw= nltk.corpus.udhr.raw(file)\n",
    "    raw_files_names[language]=raw\n",
    "  return raw_files_names\n",
    "\n",
    "def real_tokenizer(text, model_lang):\n",
    "    nlp= model_lang #Opens spacy object\n",
    "    doc=nlp(text) #Process text with spacy \n",
    "    tokens= [] #for storing tokens\n",
    "    for token in doc:\n",
    "        x= token.text #gets text from token\n",
    "        tokens.append(x)\n",
    "    return tokens\n",
    "\n",
    "def tokens(dict_raw_texts, languages): #takes real_tokenizer and filters by language to tokenize\n",
    "    tokens_langs= {} #dictionary to store output\n",
    "    for lang in languages:\n",
    "        if lang == 'Spanish':\n",
    "            text= dict_raw_texts[lang] #gets text from dict in raw_files_names \n",
    "            model_lang= nlp_es #loads corresponding model\n",
    "            tokens= tokenizer(text, model_lang) #tokenizes \n",
    "            tokens_langs[lang]=tokens #appends to output dictionary \n",
    "        elif lang == 'Korean':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_ko\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Finnish':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_fi\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Chinese':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_zh\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Japanese':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_ja\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Polish':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_pl\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'German':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_de\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Turkish':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_tr\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Indonesian':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_id\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Arabic':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_ar\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Tagalog':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_tl\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Basque':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_eu\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Estonian':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_et\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Kannada':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_kn\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Yoruba':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_yo\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Malay':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_ms\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        #elif lang == 'Vietnamese':\n",
    "          #  text= dict_raw_texts[lang]\n",
    "           # model_lang= nlp_vi\n",
    "           # tokens= tokenizer(text, model_lang)\n",
    "           # tokens_langs[lang]=tokens\n",
    "        elif lang == 'Setswana':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_tn\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Bulgarian':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_bg\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "        elif lang == 'Irish':\n",
    "            text= dict_raw_texts[lang]\n",
    "            model_lang= nlp_ga\n",
    "            tokens= tokenizer(text, model_lang)\n",
    "            tokens_langs[lang]=tokens\n",
    "    return tokens_langs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts= extract_raw_texts(languages) #returns a dictionary where KEY is language and VALUE a string with raw text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_languages_tokens= tokens(raw_texts, languages) #returns a dictionary where KEY is language and VALUE is list with tokens.\n",
    "print(len(all_languages_tokens)) #just for checking how many variables have been processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['『',\n",
       " '世界',\n",
       " '人権',\n",
       " '宣言',\n",
       " '』',\n",
       " '\\n \\n\\n',\n",
       " '（',\n",
       " '1948',\n",
       " '.',\n",
       " '12',\n",
       " '.',\n",
       " '10',\n",
       " '第',\n",
       " '３',\n",
       " '回',\n",
       " '国連',\n",
       " '総会',\n",
       " '採択',\n",
       " '）',\n",
       " '\\n\\n \\n\\n',\n",
       " '〈',\n",
       " '前文',\n",
       " '〉',\n",
       " '\\n\\u3000\\n',\n",
       " '人類',\n",
       " '社会',\n",
       " 'の',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '構成',\n",
       " '員',\n",
       " 'の',\n",
       " '固有',\n",
       " 'の',\n",
       " '尊厳',\n",
       " 'と',\n",
       " '平等',\n",
       " 'で',\n",
       " '譲る',\n",
       " 'こと',\n",
       " 'の',\n",
       " 'でき',\n",
       " 'ない',\n",
       " '権利',\n",
       " 'と',\n",
       " 'を',\n",
       " '承認',\n",
       " 'する',\n",
       " 'こと',\n",
       " 'は',\n",
       " '、',\n",
       " '世界',\n",
       " 'に',\n",
       " 'おけ',\n",
       " 'る',\n",
       " '自由',\n",
       " '、',\n",
       " '正義',\n",
       " '及び',\n",
       " '平和',\n",
       " 'の',\n",
       " '基礎',\n",
       " 'で',\n",
       " 'ある',\n",
       " 'の',\n",
       " 'で',\n",
       " '、',\n",
       " '\\n\\n',\n",
       " '人権',\n",
       " 'の',\n",
       " '無視',\n",
       " '及び',\n",
       " '軽侮',\n",
       " 'が',\n",
       " '、',\n",
       " '人類',\n",
       " 'の',\n",
       " '良心',\n",
       " 'を',\n",
       " '踏み',\n",
       " 'にじっ',\n",
       " 'た',\n",
       " '野蛮',\n",
       " '行為',\n",
       " 'を',\n",
       " 'もたらし',\n",
       " '、',\n",
       " '言論',\n",
       " '及び',\n",
       " '信仰',\n",
       " 'の',\n",
       " '自由',\n",
       " 'が',\n",
       " '受け',\n",
       " 'られ',\n",
       " '、',\n",
       " '恐怖',\n",
       " '及び',\n",
       " '欠乏',\n",
       " 'の',\n",
       " 'ない',\n",
       " '世界',\n",
       " 'の',\n",
       " '到来',\n",
       " 'が',\n",
       " '、',\n",
       " '一般',\n",
       " 'の',\n",
       " '人々',\n",
       " 'の',\n",
       " '最高',\n",
       " 'の',\n",
       " '願望',\n",
       " 'と',\n",
       " 'し',\n",
       " 'て',\n",
       " '宣言',\n",
       " 'さ',\n",
       " 'れ',\n",
       " 'た',\n",
       " 'の',\n",
       " 'で',\n",
       " '、',\n",
       " '\\u3000\\n\\n',\n",
       " '人間',\n",
       " 'が',\n",
       " '専制',\n",
       " 'と',\n",
       " '圧迫',\n",
       " 'と',\n",
       " 'に',\n",
       " '対する',\n",
       " '最後',\n",
       " 'の',\n",
       " '手段',\n",
       " 'と',\n",
       " 'し',\n",
       " 'て',\n",
       " '反逆',\n",
       " 'に',\n",
       " '訴える',\n",
       " 'こと',\n",
       " 'が',\n",
       " 'ない',\n",
       " 'よう',\n",
       " 'に',\n",
       " 'する',\n",
       " 'ため',\n",
       " 'に',\n",
       " 'は',\n",
       " '、',\n",
       " '法',\n",
       " 'の',\n",
       " '支配',\n",
       " 'に',\n",
       " 'よっ',\n",
       " 'て',\n",
       " '人権',\n",
       " 'を',\n",
       " '保護',\n",
       " 'する',\n",
       " 'こと',\n",
       " 'が',\n",
       " '肝要',\n",
       " 'で',\n",
       " 'ある',\n",
       " 'の',\n",
       " 'で',\n",
       " '、',\n",
       " '\\n\\n',\n",
       " '諸国',\n",
       " '間',\n",
       " 'の',\n",
       " '友好',\n",
       " '関係',\n",
       " 'の',\n",
       " '発展',\n",
       " 'を',\n",
       " '促進',\n",
       " 'する',\n",
       " 'こと',\n",
       " 'が',\n",
       " '肝要',\n",
       " 'で',\n",
       " 'ある',\n",
       " 'の',\n",
       " 'で',\n",
       " '、',\n",
       " '\\n\\n',\n",
       " '国際',\n",
       " '連合',\n",
       " 'の',\n",
       " '諸国',\n",
       " '民',\n",
       " 'は',\n",
       " '、',\n",
       " '国連',\n",
       " '憲章',\n",
       " 'に',\n",
       " 'おい',\n",
       " 'て',\n",
       " '、',\n",
       " '基本',\n",
       " '的',\n",
       " '人権',\n",
       " '、',\n",
       " '人間',\n",
       " 'の',\n",
       " '尊厳',\n",
       " '及び',\n",
       " '価値',\n",
       " '並びに',\n",
       " '男女',\n",
       " 'の',\n",
       " '同権',\n",
       " 'に',\n",
       " 'つい',\n",
       " 'て',\n",
       " 'の',\n",
       " '信念',\n",
       " 'を',\n",
       " '再',\n",
       " '確認',\n",
       " 'し',\n",
       " '、',\n",
       " 'かつ',\n",
       " '、',\n",
       " '一層',\n",
       " '大きな',\n",
       " '自由',\n",
       " 'の',\n",
       " 'うち',\n",
       " 'で',\n",
       " '社会',\n",
       " '的',\n",
       " '進歩',\n",
       " 'と',\n",
       " '生活',\n",
       " '水準',\n",
       " 'の',\n",
       " '向上',\n",
       " 'と',\n",
       " 'を',\n",
       " '促進',\n",
       " 'する',\n",
       " 'こと',\n",
       " 'を',\n",
       " '決意',\n",
       " 'し',\n",
       " 'た',\n",
       " 'の',\n",
       " 'で',\n",
       " '、',\n",
       " '\\u3000\\n\\n',\n",
       " '加盟',\n",
       " '国',\n",
       " 'は',\n",
       " '、',\n",
       " '国際',\n",
       " '連合',\n",
       " 'と',\n",
       " '協力',\n",
       " 'し',\n",
       " 'て',\n",
       " '、',\n",
       " '人権',\n",
       " '及び',\n",
       " '基本',\n",
       " '的',\n",
       " '自由',\n",
       " 'の',\n",
       " '普遍',\n",
       " '的',\n",
       " 'な',\n",
       " '尊重',\n",
       " '及び',\n",
       " '遵守',\n",
       " 'の',\n",
       " '促進',\n",
       " 'を',\n",
       " '達成',\n",
       " 'する',\n",
       " 'こと',\n",
       " 'を',\n",
       " '誓約',\n",
       " 'し',\n",
       " 'た',\n",
       " 'の',\n",
       " 'で',\n",
       " '、',\n",
       " '\\n\\n\\u3000\\n',\n",
       " 'これ',\n",
       " 'ら',\n",
       " 'の',\n",
       " '権利',\n",
       " '及び',\n",
       " '自由',\n",
       " 'に',\n",
       " '対する',\n",
       " '共通',\n",
       " 'の',\n",
       " '理解',\n",
       " 'は',\n",
       " '、',\n",
       " 'この',\n",
       " '誓約',\n",
       " 'を',\n",
       " '完全',\n",
       " 'に',\n",
       " 'する',\n",
       " 'ため',\n",
       " 'に',\n",
       " 'もっとも',\n",
       " '重要',\n",
       " 'で',\n",
       " 'ある',\n",
       " 'の',\n",
       " 'で',\n",
       " '、',\n",
       " '\\u3000\\n\\n\\n',\n",
       " 'よっ',\n",
       " 'て',\n",
       " '、',\n",
       " 'ここ',\n",
       " 'に',\n",
       " '、',\n",
       " '国連',\n",
       " '総会',\n",
       " 'は',\n",
       " '、',\n",
       " '\\u3000\\n\\n\\n',\n",
       " '社会',\n",
       " 'の',\n",
       " '各',\n",
       " '個人',\n",
       " '及び',\n",
       " '各',\n",
       " '機関',\n",
       " 'が',\n",
       " '、',\n",
       " 'この',\n",
       " '世界',\n",
       " '人権',\n",
       " '宣言',\n",
       " 'を',\n",
       " '常',\n",
       " 'に',\n",
       " '念頭',\n",
       " 'に',\n",
       " '置き',\n",
       " 'ながら',\n",
       " '、',\n",
       " '加盟',\n",
       " '国',\n",
       " '自身',\n",
       " 'の',\n",
       " '人民',\n",
       " 'の',\n",
       " '間',\n",
       " 'に',\n",
       " 'も',\n",
       " '、',\n",
       " 'また',\n",
       " '、',\n",
       " '加盟',\n",
       " '国',\n",
       " 'の',\n",
       " '管轄',\n",
       " '下',\n",
       " 'に',\n",
       " 'ある',\n",
       " '地域',\n",
       " 'の',\n",
       " '人民',\n",
       " 'の',\n",
       " '間',\n",
       " 'に',\n",
       " 'も',\n",
       " '、',\n",
       " 'これ',\n",
       " 'ら',\n",
       " 'の',\n",
       " '権利',\n",
       " 'と',\n",
       " '自由',\n",
       " 'と',\n",
       " 'の',\n",
       " '尊重',\n",
       " 'を',\n",
       " '指導',\n",
       " '及び',\n",
       " '教育',\n",
       " 'に',\n",
       " 'よっ',\n",
       " 'て',\n",
       " '促進',\n",
       " 'する',\n",
       " 'こと',\n",
       " '並び',\n",
       " 'に',\n",
       " 'それ',\n",
       " 'ら',\n",
       " 'の',\n",
       " '普遍',\n",
       " '的',\n",
       " '措置',\n",
       " 'に',\n",
       " 'よっ',\n",
       " 'て',\n",
       " '確保',\n",
       " 'する',\n",
       " 'こと',\n",
       " 'に',\n",
       " '努力',\n",
       " 'する',\n",
       " 'よう',\n",
       " 'に',\n",
       " '、',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '人民',\n",
       " 'と',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '国',\n",
       " 'と',\n",
       " 'が',\n",
       " '達成',\n",
       " 'す',\n",
       " 'べき',\n",
       " '共通',\n",
       " 'の',\n",
       " '基準',\n",
       " 'と',\n",
       " 'し',\n",
       " 'て',\n",
       " '、',\n",
       " 'この',\n",
       " '人権',\n",
       " '宣言',\n",
       " 'を',\n",
       " '公布',\n",
       " 'する',\n",
       " '。',\n",
       " '\\u3000\\n\\n\\n\\u3000\\n',\n",
       " '第',\n",
       " '１',\n",
       " '条',\n",
       " '\\n',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '人間',\n",
       " 'は',\n",
       " '、',\n",
       " '生まれ',\n",
       " 'ながら',\n",
       " 'に',\n",
       " 'し',\n",
       " 'て',\n",
       " '自由',\n",
       " 'で',\n",
       " 'あり',\n",
       " '、',\n",
       " 'かつ',\n",
       " '、',\n",
       " '尊厳',\n",
       " 'と',\n",
       " '権利',\n",
       " 'と',\n",
       " 'に',\n",
       " 'つい',\n",
       " 'て',\n",
       " '平等',\n",
       " 'で',\n",
       " 'ある',\n",
       " '。',\n",
       " '人間',\n",
       " 'は',\n",
       " '、',\n",
       " '理性',\n",
       " 'と',\n",
       " '良心',\n",
       " 'と',\n",
       " 'を',\n",
       " '授け',\n",
       " 'られ',\n",
       " 'て',\n",
       " 'おり',\n",
       " '、',\n",
       " '互い',\n",
       " 'に',\n",
       " '同',\n",
       " '胞',\n",
       " 'の',\n",
       " '精神',\n",
       " 'を',\n",
       " 'もっ',\n",
       " 'て',\n",
       " '行動',\n",
       " 'し',\n",
       " 'なけれ',\n",
       " 'ば',\n",
       " 'なら',\n",
       " 'ない',\n",
       " '。',\n",
       " '\\n\\n\\n',\n",
       " '第',\n",
       " '２',\n",
       " '条',\n",
       " '\\n',\n",
       " 'すべて',\n",
       " '人',\n",
       " 'は',\n",
       " '、',\n",
       " '人種',\n",
       " '、',\n",
       " '皮膚',\n",
       " 'の',\n",
       " '色',\n",
       " '、',\n",
       " '性',\n",
       " '、',\n",
       " '言語',\n",
       " '、',\n",
       " '宗教',\n",
       " '、',\n",
       " '政治',\n",
       " '上',\n",
       " 'その',\n",
       " '他',\n",
       " 'の',\n",
       " '意見',\n",
       " '、',\n",
       " '\\u3000\\u3000\\u3000\\n\\n',\n",
       " '国民',\n",
       " '的',\n",
       " 'もしくは',\n",
       " '社会',\n",
       " '的',\n",
       " '出身',\n",
       " '、',\n",
       " '財産',\n",
       " '、',\n",
       " '門地',\n",
       " 'その',\n",
       " '他',\n",
       " 'の',\n",
       " '地位',\n",
       " '又',\n",
       " 'は',\n",
       " 'これ',\n",
       " 'に',\n",
       " '類する',\n",
       " 'い',\n",
       " '\\u3000\\u3000\\u3000\\n\\n',\n",
       " 'か',\n",
       " 'なる',\n",
       " '自由',\n",
       " 'に',\n",
       " 'よる',\n",
       " '差別',\n",
       " 'を',\n",
       " 'も',\n",
       " '受ける',\n",
       " 'こと',\n",
       " 'なく',\n",
       " '、',\n",
       " 'この',\n",
       " '宣言',\n",
       " 'に',\n",
       " '掲げる',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '権',\n",
       " '\\u3000\\u3000\\u3000\\n\\n',\n",
       " '利',\n",
       " 'と',\n",
       " '自由',\n",
       " 'と',\n",
       " 'を',\n",
       " '享有',\n",
       " 'する',\n",
       " 'こと',\n",
       " 'が',\n",
       " 'できる',\n",
       " '。',\n",
       " '\\n\\n\\n',\n",
       " 'さらに',\n",
       " '、',\n",
       " '個人',\n",
       " 'の',\n",
       " '属する',\n",
       " '国又',\n",
       " 'は',\n",
       " '地域',\n",
       " 'が',\n",
       " '独立',\n",
       " '国',\n",
       " 'で',\n",
       " 'ある',\n",
       " 'と',\n",
       " '、',\n",
       " '信託',\n",
       " '統治',\n",
       " '地域',\n",
       " 'で',\n",
       " '\\u3000\\u3000\\u3000\\n\\n',\n",
       " 'ある',\n",
       " 'と',\n",
       " '、',\n",
       " '非',\n",
       " '自治',\n",
       " '地域',\n",
       " 'で',\n",
       " 'ある',\n",
       " 'と',\n",
       " '、',\n",
       " '又',\n",
       " 'は',\n",
       " '他',\n",
       " 'の',\n",
       " 'なん',\n",
       " 'ら',\n",
       " 'か',\n",
       " 'の',\n",
       " '主権',\n",
       " '制限',\n",
       " 'の',\n",
       " '下',\n",
       " 'に',\n",
       " 'ある',\n",
       " 'と',\n",
       " '\\u3000\\u3000\\u3000\\n\\n',\n",
       " 'を',\n",
       " '問わ',\n",
       " 'ず',\n",
       " '、',\n",
       " 'その',\n",
       " '国又',\n",
       " 'は',\n",
       " '地域',\n",
       " 'の',\n",
       " '政治',\n",
       " '上',\n",
       " '、',\n",
       " '管轄',\n",
       " '上',\n",
       " '又',\n",
       " 'は',\n",
       " '国際',\n",
       " '上',\n",
       " 'の',\n",
       " '地位',\n",
       " 'に',\n",
       " '基ずく',\n",
       " 'い',\n",
       " '\\u3000\\u3000\\u3000\\n\\n',\n",
       " 'か',\n",
       " 'なる',\n",
       " '差別',\n",
       " 'も',\n",
       " 'し',\n",
       " 'て',\n",
       " 'は',\n",
       " 'なら',\n",
       " 'ない',\n",
       " '。',\n",
       " '\\n\\n\\n',\n",
       " '第',\n",
       " '３',\n",
       " '条',\n",
       " '\\n',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '人',\n",
       " 'は',\n",
       " '、',\n",
       " '生命',\n",
       " '、',\n",
       " '自由',\n",
       " '及び',\n",
       " '身体',\n",
       " 'の',\n",
       " '安全',\n",
       " 'に',\n",
       " '対する',\n",
       " '権利',\n",
       " 'を',\n",
       " '有する',\n",
       " '。',\n",
       " '\\u3000\\n\\n\\n',\n",
       " '第',\n",
       " '４',\n",
       " '条',\n",
       " '\\n',\n",
       " '何',\n",
       " '人',\n",
       " 'も',\n",
       " '、',\n",
       " '奴隷',\n",
       " 'に',\n",
       " 'さ',\n",
       " 'れ',\n",
       " '、',\n",
       " '又',\n",
       " 'は',\n",
       " '苦役',\n",
       " 'に',\n",
       " '服する',\n",
       " 'こと',\n",
       " 'は',\n",
       " 'ない',\n",
       " '。',\n",
       " '奴隷',\n",
       " '制度',\n",
       " '及び',\n",
       " '奴隷',\n",
       " '\\n\\n',\n",
       " '売買',\n",
       " 'は',\n",
       " '、',\n",
       " 'いかなる',\n",
       " '形',\n",
       " 'に',\n",
       " 'おい',\n",
       " 'て',\n",
       " 'も',\n",
       " '禁止',\n",
       " 'する',\n",
       " '。',\n",
       " '\\u3000\\n\\n\\n',\n",
       " '第',\n",
       " '５',\n",
       " '条',\n",
       " '\\n',\n",
       " '何',\n",
       " '人',\n",
       " 'も',\n",
       " '、',\n",
       " '拷問',\n",
       " '又',\n",
       " 'は',\n",
       " '残虐',\n",
       " 'な',\n",
       " '、',\n",
       " '非',\n",
       " '人道',\n",
       " '的',\n",
       " 'な',\n",
       " 'もしくは',\n",
       " '屈辱',\n",
       " '的',\n",
       " 'な',\n",
       " '取扱',\n",
       " 'もしくは',\n",
       " '刑',\n",
       " '\\n\\n',\n",
       " '罰',\n",
       " 'を',\n",
       " '受ける',\n",
       " 'こと',\n",
       " 'は',\n",
       " 'ない',\n",
       " '。',\n",
       " '\\u3000\\n\\n\\n',\n",
       " '第',\n",
       " '６',\n",
       " '条',\n",
       " '\\n',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '人',\n",
       " 'は',\n",
       " '、',\n",
       " 'いかなる',\n",
       " '場所',\n",
       " 'に',\n",
       " 'おい',\n",
       " 'て',\n",
       " 'も',\n",
       " '、',\n",
       " '法',\n",
       " 'の',\n",
       " '下',\n",
       " 'に',\n",
       " 'おい',\n",
       " 'て',\n",
       " '、',\n",
       " '人',\n",
       " 'と',\n",
       " 'し',\n",
       " 'て',\n",
       " '認',\n",
       " '\\n\\n',\n",
       " 'めら',\n",
       " 'れる',\n",
       " '権利',\n",
       " 'を',\n",
       " '有する',\n",
       " '。',\n",
       " '\\u3000\\n\\n\\n',\n",
       " '第',\n",
       " '７',\n",
       " '条',\n",
       " '\\n',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '人',\n",
       " 'は',\n",
       " '、',\n",
       " '法',\n",
       " 'の',\n",
       " '下',\n",
       " 'に',\n",
       " 'おい',\n",
       " 'て',\n",
       " '平等',\n",
       " 'で',\n",
       " 'あり',\n",
       " '、',\n",
       " 'また',\n",
       " '、',\n",
       " 'いかなる',\n",
       " '差別',\n",
       " 'も',\n",
       " 'なし',\n",
       " '\\n\\n',\n",
       " 'に',\n",
       " '法',\n",
       " 'の',\n",
       " '平等',\n",
       " 'な',\n",
       " '保護',\n",
       " 'を',\n",
       " '受ける',\n",
       " '権利',\n",
       " 'を',\n",
       " '有する',\n",
       " '。',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '人',\n",
       " 'は',\n",
       " '、',\n",
       " 'この',\n",
       " '宣言',\n",
       " 'に',\n",
       " '違反',\n",
       " '\\n\\n',\n",
       " 'する',\n",
       " 'いかなる',\n",
       " '差別',\n",
       " 'に',\n",
       " '対し',\n",
       " 'て',\n",
       " 'も',\n",
       " '、',\n",
       " 'また',\n",
       " '、',\n",
       " 'その',\n",
       " 'よう',\n",
       " 'な',\n",
       " '差別',\n",
       " 'を',\n",
       " 'そそのかす',\n",
       " 'いかな',\n",
       " '\\n\\n',\n",
       " 'る',\n",
       " '行為',\n",
       " 'に',\n",
       " '対し',\n",
       " 'て',\n",
       " 'も',\n",
       " '、',\n",
       " '平等',\n",
       " 'な',\n",
       " '保護',\n",
       " 'を',\n",
       " '受ける',\n",
       " '権利',\n",
       " 'を',\n",
       " '有する',\n",
       " '。',\n",
       " '\\u3000\\n\\n\\n',\n",
       " '第',\n",
       " '８',\n",
       " '条',\n",
       " '\\n',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '人',\n",
       " 'は',\n",
       " '、',\n",
       " '憲法',\n",
       " '又',\n",
       " 'は',\n",
       " '法律',\n",
       " 'に',\n",
       " 'よっ',\n",
       " 'て',\n",
       " '与え',\n",
       " 'られ',\n",
       " 'た',\n",
       " '基本',\n",
       " '的',\n",
       " '権利',\n",
       " 'を',\n",
       " '侵害',\n",
       " 'する',\n",
       " '\\n\\n',\n",
       " '行為',\n",
       " 'に',\n",
       " '対し',\n",
       " '、',\n",
       " '権限',\n",
       " 'を',\n",
       " '有する',\n",
       " '国内',\n",
       " '裁判',\n",
       " '所',\n",
       " 'に',\n",
       " 'よる',\n",
       " '効果',\n",
       " '的',\n",
       " 'な',\n",
       " '救済',\n",
       " 'を',\n",
       " '受ける',\n",
       " '権利',\n",
       " 'を',\n",
       " '\\n\\n',\n",
       " '有する',\n",
       " '。',\n",
       " '\\u3000\\n\\n\\n',\n",
       " '第',\n",
       " '９',\n",
       " '条',\n",
       " '\\n',\n",
       " '何',\n",
       " '人',\n",
       " 'も',\n",
       " '、',\n",
       " 'ほしいまま',\n",
       " 'に',\n",
       " '逮捕',\n",
       " '、',\n",
       " '拘禁',\n",
       " '、',\n",
       " '又',\n",
       " 'は',\n",
       " '追放',\n",
       " 'さ',\n",
       " 'れる',\n",
       " 'こと',\n",
       " 'は',\n",
       " 'ない',\n",
       " '。',\n",
       " '\\u3000\\n\\n\\n',\n",
       " '第',\n",
       " '10',\n",
       " '条',\n",
       " '\\n',\n",
       " 'すべて',\n",
       " 'の',\n",
       " '人',\n",
       " 'は',\n",
       " '、',\n",
       " '自己',\n",
       " 'の',\n",
       " '権利',\n",
       " '及び',\n",
       " '義務',\n",
       " '並びに',\n",
       " '自己',\n",
       " 'に',\n",
       " '対する',\n",
       " '刑事',\n",
       " '責任',\n",
       " 'が',\n",
       " '決',\n",
       " '\\n\\n',\n",
       " '定',\n",
       " 'さ',\n",
       " 'れる',\n",
       " 'に',\n",
       " '当たっ',\n",
       " 'て',\n",
       " '、',\n",
       " '独立',\n",
       " 'の',\n",
       " '公平',\n",
       " 'な',\n",
       " '裁判',\n",
       " '所',\n",
       " 'に',\n",
       " 'よる',\n",
       " '公平',\n",
       " 'な',\n",
       " '公開',\n",
       " 'の',\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you want to check on the individual variables \n",
    "all_languages_tokens['Japanese']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
